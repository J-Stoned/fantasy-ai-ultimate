2025-07-02 14:37:02.733055: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-07-02 14:37:02.737099: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.8/lib64:
2025-07-02 14:37:02.737132: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2025-07-02 14:37:02.758120: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-07-02 14:37:02.789982: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node
Your kernel may have been built without NUMA support.
2025-07-02 14:37:02.791017: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.8/lib64:
2025-07-02 14:37:02.791909: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.8/lib64:
2025-07-02 14:37:02.792820: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.8/lib64:
2025-07-02 14:37:02.793636: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.8/lib64:
2025-07-02 14:37:02.794524: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.8/lib64:
2025-07-02 14:37:02.795420: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.8/lib64:
2025-07-02 14:37:02.796311: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.8/lib64:
2025-07-02 14:37:02.797215: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.8/lib64:
2025-07-02 14:37:02.797245: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...

üî• AGGRESSIVE ML TRAINING - USING ALL DATA!

üìä Loading ALL games with pagination...
  Loaded batch 1: 1000 games (total: 1000)
‚úÖ Loaded 1000 games total!
üìä Loading player stats...
‚úÖ Loaded 1000 player stats
‚úÖ Loaded stats for 156 games
üîß Building features for ALL games...
‚úÖ Created 1000 training samples!
‚úÖ Train: 700 | Val: 150 | Test: 150

üß† Building DEEP neural network...

üèãÔ∏è Training on ALL data...
Epoch 1 / 100

193ms 275us/step - acc=0.519 loss=0.712 val_acc=0.480 val_loss=0.695 
Epoch 1/100 - loss: 0.7124 - acc: 51.86% - val_acc: 48.00%
Epoch 2 / 100

131ms 187us/step - acc=0.516 loss=0.701 val_acc=0.460 val_loss=0.694 
Epoch 3 / 100

141ms 201us/step - acc=0.516 loss=0.697 val_acc=0.560 val_loss=0.693 
Epoch 4 / 100

116ms 166us/step - acc=0.503 loss=0.698 val_acc=0.560 val_loss=0.692 
Epoch 5 / 100

107ms 154us/step - acc=0.530 loss=0.695 val_acc=0.487 val_loss=0.692 
Epoch 6 / 100

104ms 148us/step - acc=0.496 loss=0.698 val_acc=0.507 val_loss=0.693 
Epoch 6/100 - loss: 0.6981 - acc: 49.57% - val_acc: 50.67%
Epoch 7 / 100

108ms 154us/step - acc=0.540 loss=0.692 val_acc=0.500 val_loss=0.695 
Epoch 8 / 100

101ms 144us/step - acc=0.526 loss=0.692 val_acc=0.480 val_loss=0.695 
Epoch 9 / 100

103ms 147us/step - acc=0.547 loss=0.686 val_acc=0.480 val_loss=0.696 
Epoch 10 / 100

109ms 156us/step - acc=0.569 loss=0.683 val_acc=0.453 val_loss=0.697 
Epoch 11 / 100

121ms 172us/step - acc=0.550 loss=0.685 val_acc=0.447 val_loss=0.698 
Epoch 11/100 - loss: 0.6850 - acc: 55.00% - val_acc: 44.67%
Epoch 12 / 100

116ms 166us/step - acc=0.547 loss=0.679 val_acc=0.427 val_loss=0.698 
Epoch 13 / 100

120ms 172us/step - acc=0.527 loss=0.686 val_acc=0.420 val_loss=0.698 
Epoch 14 / 100

138ms 197us/step - acc=0.546 loss=0.685 val_acc=0.440 val_loss=0.699 
Epoch 15 / 100

167ms 238us/step - acc=0.573 loss=0.676 val_acc=0.453 val_loss=0.699 
Epoch 16 / 100

149ms 213us/step - acc=0.546 loss=0.685 val_acc=0.460 val_loss=0.700 
Epoch 16/100 - loss: 0.6851 - acc: 54.57% - val_acc: 46.00%
Epoch 17 / 100

140ms 199us/step - acc=0.540 loss=0.691 val_acc=0.453 val_loss=0.700 
Epoch 18 / 100

120ms 171us/step - acc=0.547 loss=0.679 val_acc=0.460 val_loss=0.700 
Epoch 19 / 100

107ms 152us/step - acc=0.543 loss=0.691 val_acc=0.447 val_loss=0.700 
Epoch 20 / 100

111ms 159us/step - acc=0.561 loss=0.682 val_acc=0.433 val_loss=0.700 
Epoch 21 / 100

114ms 162us/step - acc=0.590 loss=0.669 val_acc=0.427 val_loss=0.701 
Epoch 21/100 - loss: 0.6693 - acc: 59.00% - val_acc: 42.67%
Epoch 22 / 100

123ms 176us/step - acc=0.549 loss=0.679 val_acc=0.467 val_loss=0.702 
Epoch 23 / 100

110ms 156us/step - acc=0.540 loss=0.684 val_acc=0.480 val_loss=0.702 
Epoch 24 / 100

104ms 148us/step - acc=0.543 loss=0.682 val_acc=0.493 val_loss=0.702 
Epoch 25 / 100

104ms 149us/step - acc=0.570 loss=0.676 val_acc=0.487 val_loss=0.702 
Epoch 26 / 100

119ms 170us/step - acc=0.577 loss=0.673 val_acc=0.480 val_loss=0.702 
Epoch 26/100 - loss: 0.6729 - acc: 57.71% - val_acc: 48.00%
Epoch 27 / 100

114ms 162us/step - acc=0.584 loss=0.668 val_acc=0.473 val_loss=0.703 
Epoch 28 / 100

111ms 159us/step - acc=0.569 loss=0.669 val_acc=0.500 val_loss=0.703 
Epoch 29 / 100

112ms 159us/step - acc=0.576 loss=0.671 val_acc=0.473 val_loss=0.703 
Epoch 30 / 100

114ms 163us/step - acc=0.586 loss=0.672 val_acc=0.440 val_loss=0.702 
Epoch 31 / 100

114ms 163us/step - acc=0.584 loss=0.667 val_acc=0.473 val_loss=0.702 
Epoch 31/100 - loss: 0.6667 - acc: 58.43% - val_acc: 47.33%
Epoch 32 / 100

118ms 168us/step - acc=0.540 loss=0.670 val_acc=0.480 val_loss=0.702 
Epoch 33 / 100

126ms 180us/step - acc=0.574 loss=0.668 val_acc=0.487 val_loss=0.704 
Epoch 34 / 100

111ms 159us/step - acc=0.609 loss=0.663 val_acc=0.467 val_loss=0.705 
Epoch 35 / 100

107ms 152us/step - acc=0.600 loss=0.654 val_acc=0.460 val_loss=0.706 
Epoch 36 / 100

105ms 150us/step - acc=0.576 loss=0.672 val_acc=0.473 val_loss=0.706 
Epoch 36/100 - loss: 0.6722 - acc: 57.57% - val_acc: 47.33%
Epoch 37 / 100

94ms 134us/step - acc=0.569 loss=0.664 val_acc=0.453 val_loss=0.706 
Epoch 38 / 100

97ms 138us/step - acc=0.560 loss=0.669 val_acc=0.460 val_loss=0.705 
Epoch 39 / 100

96ms 137us/step - acc=0.590 loss=0.660 val_acc=0.460 val_loss=0.705 
Epoch 40 / 100

99ms 141us/step - acc=0.571 loss=0.673 val_acc=0.467 val_loss=0.701 
Epoch 41 / 100

93ms 133us/step - acc=0.590 loss=0.657 val_acc=0.460 val_loss=0.699 
Epoch 41/100 - loss: 0.6566 - acc: 59.00% - val_acc: 46.00%
Epoch 42 / 100

96ms 137us/step - acc=0.603 loss=0.654 val_acc=0.460 val_loss=0.699 
Epoch 43 / 100

103ms 147us/step - acc=0.597 loss=0.654 val_acc=0.467 val_loss=0.700 
Epoch 44 / 100

109ms 156us/step - acc=0.607 loss=0.653 val_acc=0.487 val_loss=0.702 
Epoch 45 / 100

97ms 139us/step - acc=0.574 loss=0.667 val_acc=0.480 val_loss=0.706 
Epoch 46 / 100

104ms 148us/step - acc=0.606 loss=0.660 val_acc=0.467 val_loss=0.709 
Epoch 46/100 - loss: 0.6598 - acc: 60.57% - val_acc: 46.67%
Epoch 47 / 100

108ms 155us/step - acc=0.570 loss=0.662 val_acc=0.467 val_loss=0.700 
Epoch 48 / 100

109ms 155us/step - acc=0.554 loss=0.676 val_acc=0.453 val_loss=0.697 
Epoch 49 / 100

103ms 148us/step - acc=0.557 loss=0.666 val_acc=0.453 val_loss=0.698 
Epoch 50 / 100

103ms 148us/step - acc=0.559 loss=0.661 val_acc=0.473 val_loss=0.699 
Epoch 51 / 100

111ms 158us/step - acc=0.547 loss=0.667 val_acc=0.467 val_loss=0.700 
Epoch 51/100 - loss: 0.6670 - acc: 54.71% - val_acc: 46.67%
Epoch 52 / 100

102ms 146us/step - acc=0.599 loss=0.649 val_acc=0.487 val_loss=0.700 
Epoch 53 / 100

110ms 157us/step - acc=0.620 loss=0.646 val_acc=0.487 val_loss=0.702 
Epoch 54 / 100

106ms 152us/step - acc=0.561 loss=0.671 val_acc=0.480 val_loss=0.704 
Epoch 55 / 100

94ms 134us/step - acc=0.627 loss=0.648 val_acc=0.487 val_loss=0.701 
Epoch 56 / 100

96ms 137us/step - acc=0.596 loss=0.647 val_acc=0.513 val_loss=0.699 
Epoch 56/100 - loss: 0.6473 - acc: 59.57% - val_acc: 51.33%
Epoch 57 / 100

92ms 132us/step - acc=0.593 loss=0.660 val_acc=0.487 val_loss=0.699 
Epoch 58 / 100

95ms 135us/step - acc=0.623 loss=0.637 val_acc=0.487 val_loss=0.698 
Epoch 59 / 100

106ms 151us/step - acc=0.593 loss=0.655 val_acc=0.493 val_loss=0.700 
Epoch 60 / 100

103ms 147us/step - acc=0.593 loss=0.669 val_acc=0.493 val_loss=0.702 
Epoch 61 / 100

107ms 153us/step - acc=0.604 loss=0.652 val_acc=0.493 val_loss=0.702 
Epoch 61/100 - loss: 0.6515 - acc: 60.43% - val_acc: 49.33%
Epoch 62 / 100

96ms 137us/step - acc=0.604 loss=0.649 val_acc=0.507 val_loss=0.701 
Epoch 63 / 100

110ms 158us/step - acc=0.599 loss=0.647 val_acc=0.520 val_loss=0.699 
Epoch 64 / 100

93ms 132us/step - acc=0.609 loss=0.644 val_acc=0.513 val_loss=0.698 
Epoch 65 / 100

91ms 130us/step - acc=0.606 loss=0.634 val_acc=0.480 val_loss=0.698 
Epoch 66 / 100

98ms 140us/step - acc=0.594 loss=0.646 val_acc=0.460 val_loss=0.697 
Epoch 66/100 - loss: 0.6460 - acc: 59.43% - val_acc: 46.00%
Epoch 67 / 100

98ms 139us/step - acc=0.607 loss=0.647 val_acc=0.460 val_loss=0.700 
Epoch 68 / 100

102ms 146us/step - acc=0.631 loss=0.627 val_acc=0.460 val_loss=0.706 
Epoch 69 / 100

100ms 143us/step - acc=0.626 loss=0.635 val_acc=0.480 val_loss=0.712 
Epoch 70 / 100

96ms 137us/step - acc=0.614 loss=0.636 val_acc=0.480 val_loss=0.710 
Epoch 71 / 100

100ms 143us/step - acc=0.637 loss=0.637 val_acc=0.473 val_loss=0.705 
Epoch 71/100 - loss: 0.6367 - acc: 63.71% - val_acc: 47.33%
Epoch 72 / 100

98ms 140us/step - acc=0.583 loss=0.645 val_acc=0.453 val_loss=0.705 
Epoch 73 / 100

94ms 134us/step - acc=0.631 loss=0.631 val_acc=0.460 val_loss=0.709 
Epoch 74 / 100

96ms 138us/step - acc=0.620 loss=0.630 val_acc=0.447 val_loss=0.712 
Epoch 75 / 100

97ms 139us/step - acc=0.671 loss=0.622 val_acc=0.467 val_loss=0.717 
Epoch 76 / 100

92ms 132us/step - acc=0.630 loss=0.644 val_acc=0.460 val_loss=0.719 
Epoch 76/100 - loss: 0.6439 - acc: 63.00% - val_acc: 46.00%
Epoch 77 / 100

102ms 146us/step - acc=0.634 loss=0.634 val_acc=0.473 val_loss=0.719 
Epoch 78 / 100

104ms 149us/step - acc=0.623 loss=0.642 val_acc=0.467 val_loss=0.717 
Epoch 79 / 100

91ms 131us/step - acc=0.619 loss=0.635 val_acc=0.473 val_loss=0.715 
Epoch 80 / 100

121ms 174us/step - acc=0.614 loss=0.636 val_acc=0.460 val_loss=0.714 
Epoch 81 / 100

88ms 125us/step - acc=0.614 loss=0.639 val_acc=0.453 val_loss=0.712 
Epoch 81/100 - loss: 0.6392 - acc: 61.43% - val_acc: 45.33%
Epoch 82 / 100

92ms 131us/step - acc=0.597 loss=0.640 val_acc=0.440 val_loss=0.711 
Epoch 83 / 100

96ms 138us/step - acc=0.627 loss=0.632 val_acc=0.467 val_loss=0.710 
Epoch 84 / 100

91ms 130us/step - acc=0.606 loss=0.635 val_acc=0.467 val_loss=0.711 
Epoch 85 / 100

86ms 123us/step - acc=0.621 loss=0.625 val_acc=0.447 val_loss=0.712 
Epoch 86 / 100

86ms 122us/step - acc=0.631 loss=0.620 val_acc=0.453 val_loss=0.714 
Epoch 86/100 - loss: 0.6204 - acc: 63.14% - val_acc: 45.33%
Epoch 87 / 100

86ms 123us/step - acc=0.644 loss=0.627 val_acc=0.473 val_loss=0.716 
Epoch 88 / 100

84ms 120us/step - acc=0.629 loss=0.625 val_acc=0.447 val_loss=0.713 
Epoch 89 / 100

87ms 124us/step - acc=0.619 loss=0.632 val_acc=0.480 val_loss=0.712 
Epoch 90 / 100

87ms 125us/step - acc=0.639 loss=0.616 val_acc=0.460 val_loss=0.710 
Epoch 91 / 100

92ms 131us/step - acc=0.643 loss=0.613 val_acc=0.453 val_loss=0.711 
Epoch 91/100 - loss: 0.6135 - acc: 64.29% - val_acc: 45.33%
Epoch 92 / 100

88ms 126us/step - acc=0.661 loss=0.612 val_acc=0.440 val_loss=0.713 
Epoch 93 / 100

85ms 121us/step - acc=0.629 loss=0.625 val_acc=0.453 val_loss=0.715 
Epoch 94 / 100

89ms 127us/step - acc=0.621 loss=0.629 val_acc=0.447 val_loss=0.716 
Epoch 95 / 100

86ms 123us/step - acc=0.607 loss=0.634 val_acc=0.440 val_loss=0.717 
Epoch 96 / 100

88ms 126us/step - acc=0.624 loss=0.614 val_acc=0.447 val_loss=0.714 
Epoch 96/100 - loss: 0.6143 - acc: 62.43% - val_acc: 44.67%
Epoch 97 / 100

86ms 123us/step - acc=0.663 loss=0.612 val_acc=0.487 val_loss=0.715 
Epoch 98 / 100

86ms 123us/step - acc=0.613 loss=0.634 val_acc=0.480 val_loss=0.716 
Epoch 99 / 100

87ms 124us/step - acc=0.613 loss=0.632 val_acc=0.467 val_loss=0.713 
Epoch 100 / 100

86ms 123us/step - acc=0.619 loss=0.619 val_acc=0.453 val_loss=0.712 

üéØ FINAL TEST ACCURACY: 46.00%

üî• TRAINING COMPLETE!
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
üìä Samples: 1000
üéØ Accuracy: 46.00%
‚è±Ô∏è  Time: 11.1s
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

