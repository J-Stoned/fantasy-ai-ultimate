version: '3.8'

x-common-env: &common-env
  NODE_ENV: production
  DATABASE_URL: ${DATABASE_URL}
  REDIS_URL: redis://redis:6379
  KAFKA_BROKERS: kafka-1:9092,kafka-2:9092,kafka-3:9092
  NEXT_PUBLIC_SUPABASE_URL: ${NEXT_PUBLIC_SUPABASE_URL}
  NEXT_PUBLIC_SUPABASE_ANON_KEY: ${NEXT_PUBLIC_SUPABASE_ANON_KEY}
  SUPABASE_SERVICE_ROLE_KEY: ${SUPABASE_SERVICE_ROLE_KEY}

x-gpu-env: &gpu-env
  NVIDIA_VISIBLE_DEVICES: all
  NVIDIA_DRIVER_CAPABILITIES: compute,utility
  CUDA_VISIBLE_DEVICES: 0
  TF_FORCE_GPU_ALLOW_GROWTH: true
  TF_CPP_MIN_LOG_LEVEL: 2

services:
  # CORE INFRASTRUCTURE
  redis:
    image: redis:7-alpine
    command: redis-server --appendonly yes --maxmemory 2gb --maxmemory-policy allkeys-lru
    volumes:
      - redis_data:/data
    deploy:
      replicas: 1
      resources:
        limits:
          memory: 2.5G
    networks:
      - backend

  # KAFKA CLUSTER
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    volumes:
      - zookeeper_data:/var/lib/zookeeper/data
      - zookeeper_logs:/var/lib/zookeeper/log
    networks:
      - backend

  kafka-1:
    image: confluentinc/cp-kafka:7.5.0
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka-1:9092,EXTERNAL://localhost:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 2
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_LOG_RETENTION_HOURS: 168
      KAFKA_LOG_SEGMENT_BYTES: 1073741824
      KAFKA_NUM_PARTITIONS: 8
    volumes:
      - kafka1_data:/var/lib/kafka/data
    networks:
      - backend

  kafka-2:
    image: confluentinc/cp-kafka:7.5.0
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 2
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka-2:9092,EXTERNAL://localhost:29093
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 2
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
    volumes:
      - kafka2_data:/var/lib/kafka/data
    networks:
      - backend

  kafka-3:
    image: confluentinc/cp-kafka:7.5.0
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 3
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka-3:9092,EXTERNAL://localhost:29094
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 2
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
    volumes:
      - kafka3_data:/var/lib/kafka/data
    networks:
      - backend

  # MICROSERVICES
  turbo-predictions:
    build:
      context: .
      dockerfile: Dockerfile.services
      target: turbo-predictions
    environment:
      <<: *common-env
      <<: *gpu-env
      SERVICE_NAME: turbo-predictions
      REPLICAS: ${TURBO_REPLICAS:-10}
    deploy:
      replicas: 10
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
        limits:
          memory: 4G
      restart_policy:
        condition: any
        delay: 5s
        max_attempts: 3
    networks:
      - backend
    depends_on:
      - redis
      - kafka-1
      - kafka-2
      - kafka-3

  websocket-cluster:
    build:
      context: .
      dockerfile: Dockerfile.services
      target: websocket
    environment:
      <<: *common-env
      SERVICE_NAME: websocket
      PORT: 8080
    deploy:
      replicas: 5
      resources:
        limits:
          memory: 1G
      labels:
        - "traefik.enable=true"
        - "traefik.http.routers.ws.rule=Host(`ws.fantasy-ai.com`)"
        - "traefik.http.services.ws.loadbalancer.server.port=8080"
        - "traefik.http.services.ws.loadbalancer.sticky.cookie=true"
    networks:
      - backend
      - frontend

  continuous-learning:
    build:
      context: .
      dockerfile: Dockerfile.services
      target: ml-learning
    environment:
      <<: *common-env
      <<: *gpu-env
      SERVICE_NAME: continuous-learning
    deploy:
      replicas: 2
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
        limits:
          memory: 8G
    networks:
      - backend
    depends_on:
      - redis
      - kafka-1

  data-collector:
    build:
      context: .
      dockerfile: Dockerfile.services
      target: data-collector
    environment:
      <<: *common-env
      SERVICE_NAME: data-collector
      COLLECT_INTERVAL: 300000
    deploy:
      replicas: 3
      resources:
        limits:
          memory: 2G
    networks:
      - backend
    depends_on:
      - redis
      - kafka-1

  api-gateway:
    image: traefik:v3.0
    command:
      - "--api.insecure=true"
      - "--providers.docker=true"
      - "--providers.docker.swarmMode=true"
      - "--entrypoints.web.address=:80"
      - "--entrypoints.websecure.address=:443"
      - "--metrics.prometheus=true"
      - "--metrics.prometheus.buckets=0.1,0.3,1.2,5.0"
      - "--accesslog=true"
      - "--log.level=INFO"
    ports:
      - "80:80"
      - "443:443"
      - "8080:8080"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - traefik_certs:/certificates
    networks:
      - frontend
      - backend
    deploy:
      placement:
        constraints:
          - node.role == manager

  # MONITORING STACK
  prometheus:
    image: prom/prometheus:v2.47.0
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=30d'
      - '--web.enable-lifecycle'
      - '--web.enable-admin-api'
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_data:/prometheus
    networks:
      - monitoring
    deploy:
      resources:
        limits:
          memory: 2G

  grafana:
    image: grafana/grafana:10.2.0
    environment:
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_PASSWORD:-admin}
      GF_USERS_ALLOW_SIGN_UP: "false"
      GF_INSTALL_PLUGINS: grafana-clock-panel,grafana-simple-json-datasource,grafana-piechart-panel
    volumes:
      - ./monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards:ro
      - ./monitoring/grafana/datasources:/etc/grafana/provisioning/datasources:ro
      - grafana_data:/var/lib/grafana
    networks:
      - monitoring
      - frontend
    deploy:
      labels:
        - "traefik.enable=true"
        - "traefik.http.routers.grafana.rule=Host(`metrics.fantasy-ai.com`)"
        - "traefik.http.services.grafana.loadbalancer.server.port=3000"

  loki:
    image: grafana/loki:2.9.0
    command: -config.file=/etc/loki/local-config.yaml
    volumes:
      - ./monitoring/loki-config.yaml:/etc/loki/local-config.yaml:ro
      - loki_data:/loki
    networks:
      - monitoring

  promtail:
    image: grafana/promtail:2.9.0
    command: -config.file=/etc/promtail/config.yml
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - ./monitoring/promtail-config.yml:/etc/promtail/config.yml:ro
    networks:
      - monitoring
    deploy:
      mode: global

  # ML MODEL STORAGE
  minio:
    image: minio/minio:latest
    command: server /data --console-address ":9001"
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER:-minioadmin}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD:-minioadmin}
    volumes:
      - minio_data:/data
    ports:
      - "9000:9000"
      - "9001:9001"
    networks:
      - backend
    deploy:
      resources:
        limits:
          memory: 1G

  # WEB FRONTEND
  web:
    build:
      context: .
      dockerfile: Dockerfile
      target: runner
    environment:
      <<: *common-env
      PORT: 3000
    deploy:
      replicas: 3
      resources:
        limits:
          memory: 1G
      labels:
        - "traefik.enable=true"
        - "traefik.http.routers.web.rule=Host(`fantasy-ai.com`)"
        - "traefik.http.services.web.loadbalancer.server.port=3000"
    networks:
      - frontend
      - backend

volumes:
  redis_data:
  zookeeper_data:
  zookeeper_logs:
  kafka1_data:
  kafka2_data:
  kafka3_data:
  prometheus_data:
  grafana_data:
  loki_data:
  minio_data:
  traefik_certs:

networks:
  frontend:
    driver: overlay
    attachable: true
  backend:
    driver: overlay
    attachable: true
  monitoring:
    driver: overlay
    attachable: true